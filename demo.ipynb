{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forcasting of wind speed\n",
    "\n",
    "Here we show the demo for 1 hour ahead forcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70128, 7, 6), (10872, 7, 6))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.load_data import read_raw_data, make_ready_data\n",
    "train_data, test_data, scaler = read_raw_data()\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and output size are the number of series (cities)\n",
    "output_size = 7\n",
    "input_size = (7)\n",
    "# hidden size is number of LSTM units, this means 32 as it's BiLSTM\n",
    "hidden_size = 16\n",
    "\n",
    "# Only one layer of LSTM\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LSTM Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build time series features and labels\n",
    "from src.data_utils import build_dataloader\n",
    "hours_ahead = 1 #1 Hour ahead, This is to be changed to (5, 10, 50...etc)\n",
    "xtrain, xval, ytrain, yval = make_ready_data(train_data, feature='speed',gap=hours_ahead)\n",
    "xtest, ytest = make_ready_data(test_data, train=False, feature='speed', gap=hours_ahead)\n",
    "train_iter, val_iter, test_iter, device = build_dataloader(xtrain, xval, xtest, ytrain, yval, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import LSTM\n",
    "from src.run import run_train, validate\n",
    "from src.run import run_test\n",
    "\n",
    "# build the model\n",
    "lstm_baseline = LSTM(output_size, input_size, hidden_size, num_layers)\n",
    "lstm_baseline = lstm_baseline.to(device)\n",
    "\n",
    "# train the model\n",
    "lstm_baseline = run_train(lstm_baseline, train_iter, val_iter, num_epochs=10, features_set=1)\n",
    "\n",
    "#now we test the model\n",
    "y_true, y_preds = run_test(lstm_baseline, test_iter, scaler, features_set=1)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  11.844697\n",
      "MAE:  8.992798\n"
     ]
    }
   ],
   "source": [
    "# get evaluation metrics on test data\n",
    "from src.vis import results\n",
    "results(y_true, y_preds,feature_name = 'speed', plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AutoencoderLSTM (Composite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import AutoEncoderLSTM\n",
    "\n",
    "# build the model\n",
    "ae_lstm = AutoEncoderLSTM(output_size, input_size, hidden_size, num_layers)\n",
    "ae_lstm = ae_lstm.to(device)\n",
    "\n",
    "# train the model\n",
    "ae_lstm = run_train(ae_lstm, train_iter, val_iter, num_epochs=10, features_set=1, outputs_nr=2)\n",
    "\n",
    "#now we test the model\n",
    "y_true, y_preds = run_test(ae_lstm, test_iter, scaler, features_set=1, outputs_nr=2)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  11.77378\n",
      "MAE:  8.945175\n"
     ]
    }
   ],
   "source": [
    "# get evaluation metrics on test data\n",
    "results(y_true, y_preds, feature_name = 'speed', plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import AutoEncoderLSTM\n",
    "from src.run import run_train, validate\n",
    "from src.run import run_test\n",
    "\n",
    "# build time series features and labels\n",
    "from src.data_utils import build_dataloader\n",
    "hours_ahead = 5 #1 Hour ahead, This is to be changed to (5, 10, 50...etc)\n",
    "xtrain, xval, ytrain, yval = make_ready_data(train_data, feature='speed',gap=hours_ahead)\n",
    "xtest, ytest = make_ready_data(test_data, train=False, feature='speed', gap=hours_ahead)\n",
    "train_iter, val_iter, test_iter, device = build_dataloader(xtrain, xval, xtest, ytrain, yval, ytest)\n",
    "\n",
    "# build the model\n",
    "ae_lstm = AutoEncoderLSTM(output_size, input_size, hidden_size, num_layers)\n",
    "ae_lstm = ae_lstm.to(device)\n",
    "\n",
    "# train the model\n",
    "ae_lstm = run_train(ae_lstm, train_iter, val_iter, num_epochs=10, features_set=1, outputs_nr=2)\n",
    "\n",
    "#now we test the model\n",
    "y_true, y_preds = run_test(ae_lstm, test_iter, scaler, features_set=1, outputs_nr=2)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  17.719223\n",
      "MAE:  13.733143\n"
     ]
    }
   ],
   "source": [
    "# get evaluation metrics on test data\n",
    "from src.vis import results\n",
    "results(y_true, y_preds, feature_name = 'speed', plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [01:24<00:00, 11.09it/s]\n",
      "100%|██████████| 158/158 [00:09<00:00, 16.40it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , Train Loss:  0.006226113111005107 , Val Loss:  0.00507607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 234/938 [00:47<02:23,  4.91it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7a75ec812c54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mae_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mae_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_nr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#now we test the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/run/media/mohamed/Elements/github/weather/NLweather/NLweather/src/run.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(model, train_iter, val_iter, num_epochs, features_set, outputs_nr)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mloss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mloss1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mloss2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.models import AutoEncoderLSTM\n",
    "from src.run import run_train, validate\n",
    "from src.run import run_test\n",
    "\n",
    "# build time series features and labels\n",
    "from src.data_utils import build_dataloader\n",
    "hours_ahead = 10 #1 Hour ahead, This is to be changed to (5, 10, 50...etc)\n",
    "xtrain, xval, ytrain, yval = make_ready_data(train_data, feature='speed',gap=hours_ahead)\n",
    "xtest, ytest = make_ready_data(test_data, train=False, feature='speed', gap=hours_ahead)\n",
    "train_iter, val_iter, test_iter, device = build_dataloader(xtrain, xval, xtest, ytrain, yval, ytest)\n",
    "\n",
    "# build the model\n",
    "ae_lstm = AutoEncoderLSTM(output_size, input_size, hidden_size, num_layers)\n",
    "ae_lstm = ae_lstm.to(device)\n",
    "\n",
    "# train the model\n",
    "ae_lstm = run_train(ae_lstm, train_iter, val_iter, num_epochs=10, features_set=1, outputs_nr=2)\n",
    "\n",
    "#now we test the model\n",
    "y_true, y_preds = run_test(ae_lstm, test_iter, scaler, features_set=1, outputs_nr=2)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get evaluation metrics on test data\n",
    "from src.vis import results\n",
    "results(y_true, y_preds, feature_name = 'speed', plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import AutoEncoderLSTM\n",
    "from src.run import run_train, validate\n",
    "from src.run import run_test\n",
    "\n",
    "# build time series features and labels\n",
    "from src.data_utils import build_dataloader\n",
    "hours_ahead = 50 #1 Hour ahead, This is to be changed to (5, 10, 50...etc)\n",
    "xtrain, xval, ytrain, yval = make_ready_data(train_data, feature='speed',gap=hours_ahead)\n",
    "xtest, ytest = make_ready_data(test_data, train=False, feature='speed', gap=hours_ahead)\n",
    "train_iter, val_iter, test_iter, device = build_dataloader(xtrain, xval, xtest, ytrain, yval, ytest)\n",
    "\n",
    "# build the model\n",
    "ae_lstm = AutoEncoderLSTM(output_size, input_size, hidden_size, num_layers)\n",
    "ae_lstm = ae_lstm.to(device)\n",
    "\n",
    "# train the model\n",
    "ae_lstm = run_train(ae_lstm, train_iter, val_iter, num_epochs=10, features_set=1, outputs_nr=2)\n",
    "\n",
    "#now we test the model\n",
    "y_true, y_preds = run_test(ae_lstm, test_iter, scaler, features_set=1, outputs_nr=2)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get evaluation metrics on test data\n",
    "from src.vis import results\n",
    "results(y_true, y_preds,feature_name = 'speed', plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LSTM with BiLinear Pooling Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build time series features and labels including temperature time series\n",
    "xtrain, xval, ytrain, yval = make_ready_data(train_data, feature='speed',gap=hours_ahead)\n",
    "xtrain_temp, xval_temp, _, _ = make_ready_data(train_data, feature='temperature', gap=hours_ahead)\n",
    "xtest, ytest = make_ready_data(test_data, train=False, feature='speed', gap=hours_ahead)\n",
    "xtest_temp, _ = make_ready_data(test_data, train=False, feature='temperature', gap=hours_ahead)\n",
    "train_iter, val_iter, test_iter, device = build_dataloader(xtrain, xval, xtest, \n",
    "                                                           ytrain, yval, ytest, \n",
    "                                                           xtrain_temp, xval_temp,  \n",
    "                                                           xtest_temp, add_temp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import BiLinearPoolingLSTM\n",
    "\n",
    "lstm_model = BiLinearPoolingLSTM(output_size, input_size, hidden_size, num_layers)\n",
    "lstm_model = lstm_model.to(device)\n",
    "lstm_model = run_train(lstm_model, train_iter, val_iter, num_epochs=10)\n",
    "\n",
    "y_true, y_preds = run_test(lstm_model, test_iter, scaler)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  10.82287\n",
      "MAE:  7.305436\n"
     ]
    }
   ],
   "source": [
    "results(y_true, y_preds,feature_name = 'speed', plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forcasting of Wind Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build time series features and labels\n",
    "from src.data_utils import build_dataloader\n",
    "from src.load_data import make_wind_direction_data\n",
    "hours_ahead = 1 #1 Hour ahead, This is to be changed to (5, 10, 50...etc)\n",
    "xtrain, xval, ytrain, yval = make_wind_direction_data(train_data, gap=hours_ahead)\n",
    "xtest, ytest = make_wind_direction_data(test_data, train=False, gap=hours_ahead)\n",
    "train_iter, val_iter, test_iter, device = build_dataloader(xtrain, xval, xtest, ytrain, yval, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"input and output size are the number of series (cities) twice\n",
    "because we ave cosine and sine direction\"\"\"\n",
    "input_size = (14)\n",
    "output_size = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LSTM Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.run import run_test_direction\n",
    "\n",
    "# build the model\n",
    "lstm_baseline = LSTM(output_size, input_size, hidden_size, num_layers)\n",
    "lstm_baseline = lstm_baseline.to(device)\n",
    "\n",
    "# train the model\n",
    "lstm_baseline = run_train(lstm_baseline, train_iter, val_iter, num_epochs=10, features_set=1)\n",
    "\n",
    "#now we test the model\n",
    "y_true, y_preds = run_test_direction(lstm_baseline, test_iter, scaler, features_set=1)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  65.7913331042946\n",
      "MAE:  29.07654456432341\n"
     ]
    }
   ],
   "source": [
    "# get evaluation metrics on test data\n",
    "results(y_true, y_preds, feature_name = 'direction', plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LSTM with BiLinear Pooling Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build time series features and labels including tempreture time series\n",
    "xtrain_temp, xval_temp, _, _ = make_ready_data(train_data, feature='temperature', gap=hours_ahead)\n",
    "xtest_temp, _ = make_ready_data(test_data, train=False, feature='temperature', gap=hours_ahead)\n",
    "xtrain, xval, ytrain, yval = make_wind_direction_data(train_data, gap=hours_ahead)\n",
    "xtest, ytest = make_wind_direction_data(test_data, train=False, gap=hours_ahead)\n",
    "\n",
    "train_iter, val_iter, test_iter, device = build_dataloader(xtrain, xval, xtest, \n",
    "                                                           ytrain, yval, ytest, \n",
    "                                                           xtrain_temp, xval_temp,  \n",
    "                                                           xtest_temp, add_temp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (14, 7) # since the cosine+sine features = 14, tempretaure features = 7\n",
    "output_size = 14 \n",
    "\n",
    "lstm_model = BiLinearPoolingLSTM(output_size, input_size, hidden_size, num_layers)\n",
    "lstm_model = lstm_model.to(device)\n",
    "lstm_model = run_train(lstm_model, train_iter, val_iter, num_epochs=10)\n",
    "y_true, y_preds = run_test_direction(lstm_model, test_iter, scaler)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  58.74165284144138\n",
      "MAE:  22.95404277711164\n"
     ]
    }
   ],
   "source": [
    "# get evaluation metrics on test data\n",
    "results(y_true, y_preds, feature_name = 'direction', plots=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
